{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path += ['..']\n",
    "\n",
    "#%aimport GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "drive = '/Users/admin/PycharmProjects/GAN/DeepNeuralNet/GAN/imgs/'\n",
    "\n",
    "path = [os.path.join(drive, f) for f in os.listdir(drive) if '.png' in f]\n",
    "imgs = np.array([cv2.imread(p, False).astype('float32') for p in path])\n",
    "imgs = (imgs.reshape(*imgs.shape, 1) - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb3621a7b8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs[0][:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 56, 56, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像の複製"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'rotation_range': 20,\n",
    "    'width_shift_range': 0.1\n",
    "}\n",
    "datagen = image.ImageDataGenerator(**params)\n",
    "\n",
    "\n",
    "# ミニバッチを生成するジェネレーターを作成する。\n",
    "gen = datagen.flow(imgs, batch_size= imgs.shape[0])\n",
    "for _ in range(50):\n",
    "    imgs = np.vstack([imgs, next(gen)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12189, 56, 56, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D, Convolution2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Flatten, Dropout\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(128*7*7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Convolution2D(1, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model\n",
    "\n",
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(64, 5, 5,\n",
    "                            subsample=(2, 2),\n",
    "                            border_mode='same',\n",
    "                            input_shape=(56, 56, 1)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Convolution2D(128, 5, 5, subsample=(2, 2)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    comp =  model.compile(optimizer=\"adam\",loss = \"mse\")\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def combine_images(generated_images):\n",
    "    total = generated_images.shape[0]\n",
    "    cols = int(math.sqrt(total))\n",
    "    rows = math.ceil(float(total)/cols)\n",
    "    width, height = generated_images.shape[1:3]\n",
    "    combined_image = np.zeros((height*rows, width*cols),\n",
    "                              dtype=generated_images.dtype)\n",
    "\n",
    "    for index, image in enumerate(generated_images):\n",
    "        i = int(index/cols)\n",
    "        j = index % cols\n",
    "        combined_image[width*i:width*(i+1), height*j:height*(j+1)] = image[:, :, 0]\n",
    "    return combined_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), input_shape=(56, 56, 1..., strides=(2, 2), padding=\"same\")`\n",
      "/Users/admin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), strides=(2, 2))`\n",
      "/Users/admin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
      "  if sys.path[0] == '':\n",
      "/Users/admin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\")`\n",
      "/Users/admin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), padding=\"same\")`\n",
      "/Users/admin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (5, 5), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 95\n",
      "(128, 56, 56, 1) (672, 616)\n",
      "WARNING:tensorflow:From /Users/admin/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.7/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, g_loss: 0.637998, d_loss: 0.708882\n",
      "epoch: 0, batch: 1, g_loss: 0.678371, d_loss: 0.716459\n",
      "epoch: 0, batch: 2, g_loss: 0.713591, d_loss: 0.689126\n",
      "epoch: 0, batch: 3, g_loss: 0.760097, d_loss: 0.657743\n",
      "epoch: 0, batch: 4, g_loss: 0.782966, d_loss: 0.632794\n",
      "epoch: 0, batch: 5, g_loss: 0.787517, d_loss: 0.631466\n",
      "epoch: 0, batch: 6, g_loss: 0.782282, d_loss: 0.640126\n",
      "epoch: 0, batch: 7, g_loss: 0.768804, d_loss: 0.664096\n",
      "epoch: 0, batch: 8, g_loss: 0.743078, d_loss: 0.678469\n",
      "epoch: 0, batch: 9, g_loss: 0.735716, d_loss: 0.678797\n",
      "epoch: 0, batch: 10, g_loss: 0.725261, d_loss: 0.650343\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-a796e55e6e93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'discriminator.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-a796e55e6e93>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# generatorを更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch: %d, batch: %d, g_loss: %f, d_loss: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCH = 1\n",
    "GENERATED_IMAGE_PATH = 'generated_images/' # 生成画像の保存先\n",
    "\n",
    "def train():\n",
    "    \n",
    "    X_train = imgs\n",
    "#     X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2])\n",
    "    discriminator = discriminator_model()\n",
    "    d_opt = Adam(lr=1e-5, beta_1=0.1)\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=d_opt)\n",
    "\n",
    "    # generator+discriminator （discriminator部分の重みは固定）\n",
    "    discriminator.trainable = False\n",
    "    generator = generator_model()\n",
    "    dcgan = Sequential([generator, discriminator])\n",
    "    g_opt = Adam(lr=2e-4, beta_1=0.5)\n",
    "    dcgan.compile(loss='binary_crossentropy', optimizer=g_opt)\n",
    "\n",
    "    num_batches = int(X_train.shape[0] / BATCH_SIZE)\n",
    "    print('Number of batches:', num_batches)\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "\n",
    "        for index in range(num_batches):\n",
    "            noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "\n",
    "            # 生成画像を出力\n",
    "            if index % 500 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5 + 127.5\n",
    "                if not os.path.exists(GENERATED_IMAGE_PATH):\n",
    "                    os.mkdir(GENERATED_IMAGE_PATH)\n",
    "                Image.fromarray(image.astype(np.uint8))\\\n",
    "                    .save(GENERATED_IMAGE_PATH+\"%04d_%04d.png\" % (epoch, index))\n",
    "\n",
    "            # discriminatorを更新\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1]*BATCH_SIZE + [0]*BATCH_SIZE\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "\n",
    "            # generatorを更新\n",
    "            noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
    "            g_loss = dcgan.train_on_batch(noise, [1]*BATCH_SIZE)\n",
    "            print(\"epoch: %d, batch: %d, g_loss: %f, d_loss: %f\" % (epoch, index, g_loss, d_loss))\n",
    "\n",
    "        generator.save_weights('generator.h5')\n",
    "        discriminator.save_weights('discriminator.h5')\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
