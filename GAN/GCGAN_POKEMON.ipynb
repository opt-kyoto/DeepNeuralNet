{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /Users/admin/anaconda3/lib/python3.7/site-packages (1.4.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /Users/admin/anaconda3/lib/python3.7/site-packages (from pydot) (2.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "import pydot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEANJREFUeJzt3V+sHPV5xvHvU+M/hCQCJxi5GNWuZCq4KEayDBG9ACckLkUhF0kVUhVfWHIUpRKoqYhppSqRWsmoUuGmpbUEiiOlMUQkwkJRiHWwVVWKbA7lT0wcMAE3sY7FaQMWadW6Nnl7seOyZ845Ozs7s3/OeZ+PZO2ZObs7r3f9eOad+c2MIgIzy+U3xl2AmY2eg2+WkINvlpCDb5aQg2+WkINvlpCDb5aQg2+WUKPgS9oh6VVJr0va01ZRZjZcGnTknqQVwGvA7cBp4Dng7oj4yWKvWaXVsYbLBlqemVX7H/6L/41zqnreJQ2WsQ14PSLeAJB0ALgLWDT4a7iMm/TxBos0s16OxlRfz2uyqX818Iuu6dPFvDkk7ZY0LWn6POcaLM7M2tIk+AttTszrGyJiX0RsjYitK1ndYHFm1pYmwT8NXNM1vQGYaVaOmY1Ck+A/B2yWtEnSKuDzwMF2yjKzYRp4515EXJD0J8AzwArgsYh4pbXKzGxomuzVJyK+D3y/pVrMbEQ8cs8sIQffLCEH3ywhB98sIQffLCEH3ywhB98sIQffLCEH3ywhB98sIQffLCEH3ywhB98sIQffLCEH3ywhB98sIQffLCEH3ywhB98sIQffLCEH3ywhB98sIQffLCEH3ywhB98sIQffLCEH3ywhB98sIQffLKHK4Et6TNKspONd89ZKOiTpZPF4xXDLNLM29bPG/wawozRvDzAVEZuBqWLazJaIyuBHxD8Db5dm3wXsL37eD3ym5brMbIgG7fGviogzAMXjuvZKMrNhu2TYC5C0G9gNsIYPDHtxZtaHQdf4b0laD1A8zi72xIjYFxFbI2LrSlYPuDgza9OgwT8I7Cx+3gk81U45ZjYK/RzO+zbwI+B3JJ2WtAvYC9wu6SRwezFtZktEZY8fEXcv8quPt1yLmY2IR+6ZJTT0vfq2vL2592Nzpjft+dGYKrE6vMY3S8jBN0vIwTdLyD2+zVHu2cvKPXxVT9/9fu7/J4fX+GYJOfhmCXlTP7mNxy6dM/3ms/VeX9Ua2GTyGt8sIQffLCEH3ywh9/hLUJ1hsuUevuzws1taqakfHt47ObzGN0vIwTdLyME3S8g9/gSq6oWreuPuvn6UPXxd7vnHx2t8s4QcfLOEHHyzhNzjT6Dbtr84Z/pwRS9cPlbfZl9f1XeXf9/m2P26pwhb/7zGN0vIwTdLyME3S8g9/hhU9a7lc+Kr+ui659D3eu9RGuf+g+y8xjdLyME3S8jBN0tIETGyhX1Ya+Mm+V6bZVXH4Zfy8WpfXnu0jsYU78bbqnqe1/hmCVUGX9I1kg5LOiHpFUn3FvPXSjok6WTxeMXwyzWzNvSzxr8AfCUirgNuBr4s6XpgDzAVEZuBqWLazJaAyuP4EXEGOFP8/CtJJ4CrgbuAW4un7QeOAF8dSpUTrul55VU9ffn9y2P5/3HD5PTOXzw9t9aNvF9r1TkHVcqfw2v3PDJn+tpvfqnn672P4X21enxJG4EbgaPAVcV/Chf/c1jXdnFmNhx9B1/SB4Engfsi4t0ar9staVrS9HnODVKjmbWsr+BLWkkn9N+KiO8Ws9+StL74/XpgdqHXRsS+iNgaEVtXsrqNms2socrj+JJEp4d/OyLu65r/N8AvI2KvpD3A2oi4v9d7ZTmO/8zM3B683PdWKff85V62rO77T4ryvolP/ebcv3f5cyyr+nuf2vbfgxW2hPV7HL+fk3RuAf4Y+LGki9/EnwN7gSck7QJ+Dnxu0GLNbLT62av/L8Bi/4Ms/9W32TLkkXtmCXmsfguqjrOXlXv4quePUtX1+iap1rLldI7DoDxW38wW5eCbJeTgmyXkHn8Iqq4N1/Y+gCb7DJpeg7/JsqruD9D0/Xp9D8u1/3ePb2aLcvDNEvLltYegahO2PJS0/Pt5t9BqsOk/6sNvvTa/N9Hsc2nalizXzftBeI1vlpCDb5aQg2+WkHv8EajqXcu/rxoCXNXz1+mF67626vm9DqlVXTLsU9RbdtXnZovzGt8sIQffLCEH3ywh9/hDUHW57XJve+3e3peFrnscv9fvq96r7nH/cd7K2j394LzGN0vIwTdLyME3S8g9fguqjrufqvl+5ctply87Tc3TV7s1Hbtfdey8122t5o0RuKfZ2Pkm4xey8xrfLCEH3ywhB98sIV96awiqbqFVtxetOr+/PC5gmLfUarOPrhp7X/dSXFX7HzKcj+9Lb5nZohx8s4QcfLOE3OMPQdPbZNfVqzdu2jcvJRlvi13mHt/MFlUZfElrJB2T9JKkVyR9vZi/SdJRSSclPS5p1fDLNbM29LPGPwdsj4gbgC3ADkk3Aw8CD0XEZuAdYNfwyjSzNlWO1Y/OToD/LCZXFn8C2A58oZi/H/ga8Ej59Vat7u2d550bcGzx8fdV16Yf9rHtXtfca2remIK9cyczHLcfVF89vqQVkl4EZoFDwM+AsxFxoXjKaeDq4ZRoZm3rK/gR8V5EbAE2ANuA6xZ62kKvlbRb0rSk6fOcG7xSM2tNrb36EXEWOALcDFwu6WKrsAGYWeQ1+yJia0RsXcnqJrWaWUsqe3xJVwLnI+KspEuBT9DZsXcY+CxwANgJPDXMQidZuef+4unex8qb3N55IbWOX5f64KbXravqo7t/f7jiugVNl13+u/Tav5G9/+/nQhzrgf2SVtDZQngiIp6W9BPggKS/Al4AHh1inWbWon726r8M3LjA/Dfo9PtmtsR45J5ZQh6rPwRNzwMvj/Xvvm7dpKu8XmAPVdcuLKt7v4EMY/k9Vt/MFuXgmyXky2u3oOqQWNVtscuW0qZ92TA37cufW6+hynWXne3wntf4Zgk5+GYJOfhmCbnHH4Kml41+89m508ul/2za0ze9bJhvq/0+r/HNEnLwzRJy8M0Sco8/oO5+cV4PXupF6x7HL586u1wuiV3ed1F1y6smx+mrNL2V+VLnNb5ZQg6+WUIOvllC7vEH1N0jnqr52qqefSNz+89RXxK7iV7Hyucdty/vC6FeT191Wm6dW3rX3g+zxHmNb5aQg2+WkINvlpAvvTWgJreiruo96152utc+gFGPTy/vf+j1WdTpwaH+51I1TqDXey/VHt+X3jKzRTn4Zgk5+GYJ+Tj+gOb0p6Wx9Wzrv8+tfG+qe9t5x697nEfQds9feRurrmPzdXv6UZq3n4TJHSvRBq/xzRJy8M0ScvDNEnKPP6Amx8qbjCmfdE1vfd3kveZ9juV9Lz1M8vkPw+A1vllCfQdf0gpJL0h6upjeJOmopJOSHpe0anhlmlmb6qzx7wVOdE0/CDwUEZuBd4BdbRZmZsPTV48vaQPwB8BfA38qScB24AvFU/YDXwMeWfANlrnKY+UVx/Xb7IsnWdt/z6rrFPTa95Ktpy/rd43/MHA/8Oti+iPA2Yi4UEyfBq5uuTYzG5LK4Eu6E5iNiOe7Zy/w1AVP85O0W9K0pOnznBuwTDNrUz+b+rcAn5Z0B7AG+DCdLYDLJV1SrPU3ADMLvTgi9gH7oHNabitVm1kjtc7Hl3Qr8GcRcaek7wBPRsQBSf8AvBwRf9/r9cvpfPw2Nb1ufq9zx5+ZmdtX17l//SDq3h+vjqV07cFxGcX5+F+ls6PvdTo9/6MN3svMRqjWyL2IOAIcKX5+A9jWfklmNmwestuCqs3p8u+v/eaX5r7BtnqbrOXN6ddm5h5F7V7+qDftX7tn8Vqq2oCqTfl5f889vT/nYf/dlzIP2TVLyME3S8jBN0vIPX4Lyj17+bJN5V6z6rJOdXvV8u973sK7ZeX3v5bFP4te/T9U9/BVn0PV92Dv8xrfLCEH3ywhB98sId9Cy2wZ8S20zGxRDr5ZQg6+WUIOvllCDr5ZQg6+WUIOvllCDr5ZQg6+WUIOvllCDr5ZQg6+WUIOvllCDr5ZQg6+WUIOvllCDr5ZQg6+WUIOvllCDr5ZQg6+WUJ93UlH0ingV8B7wIWI2CppLfA4sBE4BfxhRLwznDLNrE111vi3RcSWiNhaTO8BpiJiMzBVTJvZEtBkU/8uYH/x837gM83LMbNR6Df4AfxQ0vOSdhfzroqIMwDF47qFXihpt6RpSdPnOde8YjNrrN+75d4SETOS1gGHJP203wVExD5gH3TupDNAjWbWsr7W+BExUzzOAt8DtgFvSVoPUDzODqtIM2tXZfAlXSbpQxd/Bj4JHAcOAjuLp+0EnhpWkWbWrn429a8Cvifp4vP/KSJ+IOk54AlJu4CfA58bXplm1qbK4EfEG8ANC8z/JeBb35otQR65Z5aQg2+WkINvlpCDb5aQg2+WkINvlpCDb5aQg2+WkINvlpCDb5aQg2+WkINvlpCDb5aQg2+WkINvlpCDb5aQIkZ3/UtJ/w78G/BR4D9GtuB6JrW2Sa0LXNughlHbb0XElVVPGmnw/3+h0nTXjTkmyqTWNql1gWsb1Dhr86a+WUIOvllC4wr+vjEttx+TWtuk1gWubVBjq20sPb6ZjZc39c0SGmnwJe2Q9Kqk1yWN9bbakh6TNCvpeNe8tZIOSTpZPF4xptqukXRY0glJr0i6d1Lqk7RG0jFJLxW1fb2Yv0nS0aK2xyWtGnVtRR0rJL0g6ekJq+uUpB9LelHSdDFvbN/nyIIvaQXwd8DvA9cDd0u6flTLX8A3gB2leXuAqYjYDEwV0+NwAfhKRFwH3Ax8ufisJqG+c8D2iLgB2ALskHQz8CDwUFHbO8CuMdQGcC9womt6UuoCuC0itnQdwhvf9xkRI/kDfAx4pmv6AeCBUS1/kZo2Ase7pl8F1hc/rwdeHWd9XXU9Bdw+afUBHwD+FbiJzkCUSxb6rkdYzwY6AdoOPA1oEuoqln0K+Ghp3ti+z1Fu6l8N/KJr+nQxb5JcFRFnAIrHdWOuB0kbgRuBo0xIfcXm9It07pB8CPgZcDYiLhRPGdd3+zBwP/DrYvojE1IXQAA/lPS8pN3FvLF9n/3cNLMtWmCeDyn0IOmDwJPAfRHxbnHj0rGLiPeALZIup3Pb9OsWetooa5J0JzAbEc9LuvXi7AWeOq5/c7dExIykdcAhST8dUx3AaHfunQau6ZreAMyMcPn9eEvSeoDicXZchUhaSSf034qI705afQARcRY4Qmc/xOWSLq5IxvHd3gJ8WtIp4ACdzf2HJ6AuACJipnicpfOf5TbG+H2OMvjPAZuLvayrgM8DB0e4/H4cBHYWP++k01uPnDqr9keBExHxt12/Gnt9kq4s1vRIuhT4BJ2daYeBz46rtoh4ICI2RMRGOv+2no2IPxp3XQCSLpP0oYs/A58EjjPO73PEOzjuAF6j0xP+xTh2snTV8m3gDHCeztbILjo94RRwsnhcO6bafo/OJunLwIvFnzsmoT7gd4EXitqOA39ZzP9t4BjwOvAdYPUYv9tbgacnpa6ihpeKP69c/Lc/zu/TI/fMEvLIPbOEHHyzhBx8s4QcfLOEHHyzhBx8s4QcfLOEHHyzhP4PXv1MnlZEonMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "img = image.load_img(\"./imgs/001_pika.png\")\n",
    "img = np.array(img)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(img.shape)\n",
    "plt.imshow(img[:,:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (56, 56, 3))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e7ba43e1b8e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# ミニバッチを生成するジェネレーターを作成する。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         )\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    115\u001b[0m             raise ValueError('Input data in `NumpyArrayIterator` '\n\u001b[1;32m    116\u001b[0m                              \u001b[0;34m'should have rank 4. You passed an array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                              'with shape', self.x.shape)\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mchannels_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_last'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannels_axis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (56, 56, 3))"
     ]
    }
   ],
   "source": [
    "# 画像を読み込む。\n",
    "X = []\n",
    "names = os.listdir(\"./imgs\")\n",
    "\n",
    "for name in names:\n",
    "    tmp  = image.load_img(\"./imgs/\"+ name)\n",
    "    tmp = np.array(tmp)\n",
    "    X.append(tmp)\n",
    "\n",
    "# 画像データ生成器を作成する。\n",
    "params = {\n",
    "    'rotation_range': 20,\n",
    "    'width_shift_range': 0.4\n",
    "}\n",
    "datagen = image.ImageDataGenerator(**params)\n",
    "\n",
    "\n",
    "# ミニバッチを生成するジェネレーターを作成する。\n",
    "gen = datagen.flow(X, batch_size=16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Python ジェネレーターで9枚生成して、表示する。\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(9):\n",
    "    batches = next(gen)  # (NumBatches, Height, Width, Channels) の4次元データを返す。\n",
    "    # 画像として表示するため、3次元データにし、float から uint8 にキャストする。\n",
    "    gen_img = batches[0]#.astype(np.uint8)\n",
    "    gen_img = gen_img[:,:,0]\n",
    "    print(gen_img.shape)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(gen_img)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 2, 3],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D, Convolution2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Flatten, Dropout\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(128*7*7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Reshape((128, 7, 7), input_shape=(128*7*7,)))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Convolution2D(1, 5, 5, border_mode='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model\n",
    "\n",
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(64, 5, 5,\n",
    "                            subsample=(2, 2),\n",
    "                            border_mode='same',\n",
    "                            input_shape=(1, 56, 56)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Convolution2D(128, 5, 5, subsample=(2, 2)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    comp =  model.compile(optimizer=\"adam\",loss = \"mse\")\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def combine_images(generated_images):\n",
    "    total = generated_images.shape[0]\n",
    "    cols = int(math.sqrt(total))\n",
    "    rows = math.ceil(float(total)/cols)\n",
    "    width, height = generated_images.shape[2:]\n",
    "    combined_image = np.zeros((height*rows, width*cols),\n",
    "                              dtype=generated_images.dtype)\n",
    "\n",
    "    for index, image in enumerate(generated_images):\n",
    "        i = int(index/cols)\n",
    "        j = index % cols\n",
    "        combined_image[width*i:width*(i+1), height*j:height*(j+1)] = image[0, :, :]\n",
    "    return combined_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/admin/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), input_shape=(1, 28, 28..., strides=(2, 2), padding=\"same\")`\n",
      "/Users/admin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), strides=(2, 2))`\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 5 from 1 for 'conv2d_2/convolution' (op: 'Conv2D') with input shapes: [?,1,14,64], [5,5,64,128].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 5 from 1 for 'conv2d_2/convolution' (op: 'Conv2D') with input shapes: [?,1,14,64], [5,5,64,128].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e67df9e07b72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-e67df9e07b72>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0md_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c9bfd59378df>\u001b[0m in \u001b[0;36mdiscriminator_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m                             input_shape=(1, 28, 28)))\n\u001b[1;32m     38\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mcomp\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3648\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3649\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3650\u001b[0;31m         data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         data_format=data_format)\n\u001b[0;32m--> 851\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         name=self.name)\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;34m\"Conv2D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m   1027\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1823\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 5 from 1 for 'conv2d_2/convolution' (op: 'Conv2D') with input shapes: [?,1,14,64], [5,5,64,128]."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "NUM_EPOCH = 1\n",
    "GENERATED_IMAGE_PATH = 'generated_images/' # 生成画像の保存先\n",
    "\n",
    "def train():\n",
    "    \n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2])\n",
    "    discriminator = discriminator_model()\n",
    "    d_opt = Adam(lr=1e-5, beta_1=0.1)\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=d_opt)\n",
    "\n",
    "    # generator+discriminator （discriminator部分の重みは固定）\n",
    "    discriminator.trainable = False\n",
    "    generator = generator_model()\n",
    "    dcgan = Sequential([generator, discriminator])\n",
    "    g_opt = Adam(lr=2e-4, beta_1=0.5)\n",
    "    dcgan.compile(loss='binary_crossentropy', optimizer=g_opt)\n",
    "\n",
    "    num_batches = int(X_train.shape[0] / BATCH_SIZE)\n",
    "    print('Number of batches:', num_batches)\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "\n",
    "        for index in range(num_batches):\n",
    "            noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "\n",
    "            # 生成画像を出力\n",
    "            if index % 500 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5 + 127.5\n",
    "                if not os.path.exists(GENERATED_IMAGE_PATH):\n",
    "                    os.mkdir(GENERATED_IMAGE_PATH)\n",
    "                Image.fromarray(image.astype(np.uint8))\\\n",
    "                    .save(GENERATED_IMAGE_PATH+\"%04d_%04d.png\" % (epoch, index))\n",
    "\n",
    "            # discriminatorを更新\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1]*BATCH_SIZE + [0]*BATCH_SIZE\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "\n",
    "            # generatorを更新\n",
    "            noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n",
    "            g_loss = dcgan.train_on_batch(noise, [1]*BATCH_SIZE)\n",
    "            print(\"epoch: %d, batch: %d, g_loss: %f, d_loss: %f\" % (epoch, index, g_loss, d_loss))\n",
    "\n",
    "        generator.save_weights('generator.h5')\n",
    "        discriminator.save_weights('discriminator.h5')\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 5, 5,\n",
    "                        subsample=(2, 2),\n",
    "                        border_mode='same',\n",
    "                        input_shape=(1, 28, 28)))\n",
    "model.add(LeakyReLU(0.2))\n",
    "model.add(Convolution2D(128, 5, 5, subsample=(2, 2)))\n",
    "model.add(LeakyReLU(0.2))\n",
    "model.compile(optimizer=\"adam\", loss='mean_squared_error', )\n",
    "\n",
    "(X_train, y_train), (_, _) = mnist.load_data()\n",
    "X_train = (X_train[:10].astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "model.fit(X_train, batch_size=1, epochs=1,validation_steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 346,
   "position": {
    "height": "40px",
    "left": "1163px",
    "right": "20px",
    "top": "126px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
